{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Protocol Privacy Engineering Certification\n",
    "\n",
    "## Module 4 - Data Sharing Live Lab\n",
    "\n",
    "![Data Protocol Privacy Engineering Certification](images/nishant_pe.png)\n",
    "\n",
    "This workbook is part of the [Data Protocol Privacy Engineering Certification](https://dataprotocol.com/). Working with data and anonymizing data is a growing essential skill that has to be learned as well as applied. To fully understand and benefit from this workbook, take the [course](https://dataprotocol.com/), read the [book](https://www.manning.com/books/privacy-engineering), and get certified!\n",
    "\n",
    "This is a Juypter Labs workbook that supports module 4 \"Data Sharing\", If you are completely new to Jupyter workbooks and want to understand how to use, please watch [this short video](https://youtu.be/A5YyoCKxEOU?t=106) to learn the basics."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "This introduction looks at common data sharing techniques introduced in the course, applied in code and with data. One is k-anonymity, a privacy model commonly applied to protect data subjects’ privacy in data sharing scenarios, and the guarantees that k-anonymity can provide when used to anonymise data. Another is l-diversity.\n",
    "\n",
    "Sharing data is a very important decision to take. It is impossible to get data back once shared and liabilities can be tremendously high, especially if the data being shared can be used to identify individuals and lead to a loss of privacy. You may have tried really hard to anonymize the data being released but legal organizations want to trust more than your word. K-anonymity serves that need by providing one mechanism to quantify the risk contained in any released dataset, it moves the conversation from subjective opinion to factual basis.\n",
    "\n",
    "Our dataset comes represents trips taken in New York during the month of January 2015. We will be looking at thousands of rides with very rich data attached.  This dataset in entirety should never be released externally since re-identification would be easy.  Inside the dataset there are four columns that represent where each ride has a pickup location and a drop off location. For each location, we will vary the number of decimal points in their GPS coordinates so that we can provide that same location with varying degrees of precision. Based on this variation in precision, we will see how many other rides meet the same criteria and what the associated privacy values are.\n",
    "\n",
    "## Preparing the Lab\n",
    "\n",
    "We are going to use python for this exercise since python has many libraries for supporting large datasets such as pandas and numpy, all packaged by [scipy.org](https://scipy.org).  We are not going to do anything advanced so we hope you can follow along and focus on the privacy aspects even if you are not a regular python coder.  We have designed the code so even if you are not an expert, you should be able to play with the varying input criteria and see the effects on output.\n",
    "\n",
    "It is necessary to execute each line of the code starting from the top of the workbook.  You can re-execute individual cells after changing the contained code if wanted.\n",
    "\n",
    "## The Dataset\n",
    "\n",
    "We will first import the main libraries we will be using - pandas and numpy.  This makes working with large datasets very easy. We then load in the master trip dataset that our engineers have generated for us."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./lib/\")\n",
    "import progressCheck\n",
    "\n",
    "# Set for nice formatting of table\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "master_df = pd.read_csv(\n",
    "    \"passenger-trips.csv\",\n",
    "    dtype={\"Sex\": str},\n",
    "    parse_dates=[\"Pickup\", \"Dropoff\", \"DOB\"],\n",
    ")\n",
    "\n",
    "master_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/geoffhollingworth/dev/dp/k-anonymity/venv/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97950 entries, 0 to 97949\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Pickup        97950 non-null  datetime64[ns]\n",
      " 1   Dropoff       97950 non-null  datetime64[ns]\n",
      " 2   Pickup_long   97950 non-null  float64       \n",
      " 3   Pickup_lat    97950 non-null  float64       \n",
      " 4   Dropoff_long  97950 non-null  float64       \n",
      " 5   Dropoff_lat   97950 non-null  float64       \n",
      " 6   Sex           97950 non-null  object        \n",
      " 7   DOB           97950 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(4), object(1)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(\"Master Dataset size = \", len(master_df), '\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Master Dataset size =  97950 \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "display (master_df.head(3))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "               Pickup             Dropoff  Pickup_long  Pickup_lat  \\\n",
       "0 2015-01-15 19:05:39 2015-01-15 19:23:42   -73.993896   40.750111   \n",
       "1 2015-01-10 20:33:38 2015-01-10 20:53:28   -74.001648   40.724243   \n",
       "2 2015-01-10 20:33:38 2015-01-10 20:43:41   -73.963341   40.802788   \n",
       "\n",
       "   Dropoff_long  Dropoff_lat Sex        DOB  \n",
       "0    -73.974785    40.750618   M 1968-08-04  \n",
       "1    -73.994415    40.759109   F 1980-07-23  \n",
       "2    -73.951820    40.824413   M 1996-07-06  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pickup</th>\n",
       "      <th>Dropoff</th>\n",
       "      <th>Pickup_long</th>\n",
       "      <th>Pickup_lat</th>\n",
       "      <th>Dropoff_long</th>\n",
       "      <th>Dropoff_lat</th>\n",
       "      <th>Sex</th>\n",
       "      <th>DOB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-15 19:05:39</td>\n",
       "      <td>2015-01-15 19:23:42</td>\n",
       "      <td>-73.993896</td>\n",
       "      <td>40.750111</td>\n",
       "      <td>-73.974785</td>\n",
       "      <td>40.750618</td>\n",
       "      <td>M</td>\n",
       "      <td>1968-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10 20:33:38</td>\n",
       "      <td>2015-01-10 20:53:28</td>\n",
       "      <td>-74.001648</td>\n",
       "      <td>40.724243</td>\n",
       "      <td>-73.994415</td>\n",
       "      <td>40.759109</td>\n",
       "      <td>F</td>\n",
       "      <td>1980-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-10 20:33:38</td>\n",
       "      <td>2015-01-10 20:43:41</td>\n",
       "      <td>-73.963341</td>\n",
       "      <td>40.802788</td>\n",
       "      <td>-73.951820</td>\n",
       "      <td>40.824413</td>\n",
       "      <td>M</td>\n",
       "      <td>1996-07-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have printed the top 3 rows of the data. You can see the data is incredibly detailed both from a time and location point of view.  The data covers all trips taken in the New York area in the month of January, 2015.  This is a data set that looks anonymous at first glance since there is no clear Personally Identifying Information (PII) visible.  But it is exactly the opposite, it is rich in quasi-identifiers and location data is always sensitive. Both can be combined with other datasets and generally available knowledge to de-anonymize the data.  \n",
    "\n",
    "This workbook shall use this dataset as the master dataset to create secondary privacy centric datasets, that are \"safe\" to release while maintaining analytics value for the receiver.\n",
    "\n",
    "### Important Note\n",
    "\n",
    "Privacy analysis (inventory, categorization, sharing) is not absolute, do once and never more.  It depends on what data is needed, how big the dataset is, what the context of the dataset is, what specific data is in the specific dataset.  This workbook teaches techniques for data sharing that should be continuously applied.\n",
    "\n",
    "## End to End Trip Analysis\n",
    "\n",
    "The first analyses the pick up and drop off location data that can be released to enable end to end trip analysis by a third party.  We use k-anonymity and l-diversity to understand and quantify the risks contained in the data. This quantified risk analysis allows objective discussions with your legal and risk management experts, to decide what should be released and when.\n",
    "\n",
    "### K-Anonymity\n",
    "\n",
    "To help, we will create helper functions as we introduce new techniques to study our dataset.  Our first analysis extracts the location data from the master dataset, adjusts the decimal point accurary and runs k-anonymity on the resulting dataset, to capture % compliance levels.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Python iteration generator function\n",
    "def gps_reduce(gps_df):\n",
    "    for dp in range(5):\n",
    "        gps_reduced = gps_df.round(decimals=dp)\n",
    "        yield dp, gps_reduced\n",
    "\n",
    "\n",
    "# run analysis of data precision versus wanted k-anonymity value\n",
    "def create_k_anon_matrix(df, transform, k_anon_values):\n",
    "\n",
    "    k_anon_matrix = pd.DataFrame({}, columns=k_anon_values)\n",
    "\n",
    "    for row_name, gps_reduced in transform(df):\n",
    "        frequencies = gps_reduced.value_counts(ascending=True)\n",
    "        k_result_values = {}\n",
    "\n",
    "        for k in k_anon_values:\n",
    "            match = frequencies[frequencies >= k].sum()\n",
    "            total = frequencies.sum()\n",
    "            result = round(match / total * 100, 2)\n",
    "            k_result_values[k] = result\n",
    "\n",
    "        row = pd.Series(k_result_values)\n",
    "        row.name = row_name\n",
    "        k_anon_matrix = k_anon_matrix.append(row)\n",
    "\n",
    "    return k_anon_matrix\n",
    "\n",
    "# Call the functions for analysis\n",
    "\n",
    "k_anon_values = [2, 5, 10, 50, 100, 1000]\n",
    "working_df = master_df[[\"Pickup_long\", \"Pickup_lat\", \"Dropoff_long\", \"Dropoff_lat\"]].copy()\n",
    "result = create_k_anon_matrix(working_df, gps_reduce, k_anon_values)\n",
    "\n",
    "result.style.format(\"{:,.1f}%\").set_caption(\n",
    "        \"% K-Anon Compliance: x = k value, rows = gps decimal points\\n Dataset size = \" + str(len (working_df))\n",
    "    ) "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11cd754e0>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b3ce3_\">\n",
       "  <caption>% K-Anon Compliance: x = k value, rows = gps decimal points\n",
       " Dataset size = 97950</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >2</th>\n",
       "      <th class=\"col_heading level0 col1\" >5</th>\n",
       "      <th class=\"col_heading level0 col2\" >10</th>\n",
       "      <th class=\"col_heading level0 col3\" >50</th>\n",
       "      <th class=\"col_heading level0 col4\" >100</th>\n",
       "      <th class=\"col_heading level0 col5\" >1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b3ce3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b3ce3_row0_col0\" class=\"data row0 col0\" >100.0%</td>\n",
       "      <td id=\"T_b3ce3_row0_col1\" class=\"data row0 col1\" >100.0%</td>\n",
       "      <td id=\"T_b3ce3_row0_col2\" class=\"data row0 col2\" >100.0%</td>\n",
       "      <td id=\"T_b3ce3_row0_col3\" class=\"data row0 col3\" >100.0%</td>\n",
       "      <td id=\"T_b3ce3_row0_col4\" class=\"data row0 col4\" >100.0%</td>\n",
       "      <td id=\"T_b3ce3_row0_col5\" class=\"data row0 col5\" >100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3ce3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b3ce3_row1_col0\" class=\"data row1 col0\" >99.9%</td>\n",
       "      <td id=\"T_b3ce3_row1_col1\" class=\"data row1 col1\" >99.8%</td>\n",
       "      <td id=\"T_b3ce3_row1_col2\" class=\"data row1 col2\" >99.7%</td>\n",
       "      <td id=\"T_b3ce3_row1_col3\" class=\"data row1 col3\" >99.2%</td>\n",
       "      <td id=\"T_b3ce3_row1_col4\" class=\"data row1 col4\" >98.4%</td>\n",
       "      <td id=\"T_b3ce3_row1_col5\" class=\"data row1 col5\" >93.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3ce3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b3ce3_row2_col0\" class=\"data row2 col0\" >95.2%</td>\n",
       "      <td id=\"T_b3ce3_row2_col1\" class=\"data row2 col1\" >88.7%</td>\n",
       "      <td id=\"T_b3ce3_row2_col2\" class=\"data row2 col2\" >82.9%</td>\n",
       "      <td id=\"T_b3ce3_row2_col3\" class=\"data row2 col3\" >61.9%</td>\n",
       "      <td id=\"T_b3ce3_row2_col4\" class=\"data row2 col4\" >41.8%</td>\n",
       "      <td id=\"T_b3ce3_row2_col5\" class=\"data row2 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3ce3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b3ce3_row3_col0\" class=\"data row3 col0\" >6.8%</td>\n",
       "      <td id=\"T_b3ce3_row3_col1\" class=\"data row3 col1\" >0.2%</td>\n",
       "      <td id=\"T_b3ce3_row3_col2\" class=\"data row3 col2\" >0.0%</td>\n",
       "      <td id=\"T_b3ce3_row3_col3\" class=\"data row3 col3\" >0.0%</td>\n",
       "      <td id=\"T_b3ce3_row3_col4\" class=\"data row3 col4\" >0.0%</td>\n",
       "      <td id=\"T_b3ce3_row3_col5\" class=\"data row3 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3ce3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b3ce3_row4_col0\" class=\"data row4 col0\" >0.1%</td>\n",
       "      <td id=\"T_b3ce3_row4_col1\" class=\"data row4 col1\" >0.0%</td>\n",
       "      <td id=\"T_b3ce3_row4_col2\" class=\"data row4 col2\" >0.0%</td>\n",
       "      <td id=\"T_b3ce3_row4_col3\" class=\"data row4 col3\" >0.0%</td>\n",
       "      <td id=\"T_b3ce3_row4_col4\" class=\"data row4 col4\" >0.0%</td>\n",
       "      <td id=\"T_b3ce3_row4_col5\" class=\"data row4 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Along the x axis are increasing k values so for example the last column is the percentage of records that have 999 other identical entries.  The Y column is the precision of the data, moving from 0 decimal places of gps accurracy to 4 decimal places of gps accurary.  \n",
    "\n",
    "This table should not be surprising if we understand how the accuracy of gps locations works.\n",
    "\n",
    "The gps coordinates have 15 decimal places.  Using acuracy information on [gis.stackexhange.com](https://gis.stackexchange.com/questions/8650/measuring-accuracy-of-latitude-and-longitude/) we see...\n",
    "\n",
    "- The tens digit gives a position to about 1,000 kilometers. It gives us useful information about what continent or ocean we are on.\n",
    "- The units digit (one decimal degree) gives a position up to 111 kilometers (60 nautical miles, about 69 miles). It can tell us roughly what large state or country we are in.\n",
    "- The first decimal place is worth up to 11.1 km: it can distinguish the position of one large city from a neighboring large city.\n",
    "- The second decimal place is worth up to 1.1 km: it can separate one village from the next.\n",
    "- The third decimal place is worth up to 110 m: it can identify a large agricultural field or institutional campus.\n",
    "- The fourth decimal place is worth up to 11 m: it can identify a parcel of land. It is comparable to the typical accuracy of an uncorrected GPS unit with no interference.\n",
    "- The fifth decimal place is worth up to 1.1 m: it distinguish trees from each other. Accuracy to this level with commercial GPS units can only be achieved with differential correction.\n",
    "- The sixth decimal place is worth up to 0.11 m: you can use this for laying out structures in detail, for designing landscapes, building roads. It should be more than good enough for tracking movements of glaciers and rivers. This can be achieved by taking painstaking measures with GPS, such as differentially corrected GPS.\n",
    "- The seventh decimal place is worth up to 11 mm: this is good for much surveying and is near the limit of what GPS-based techniques can achieve.\n",
    "- The eighth decimal place is worth up to 1.1 mm: this is good for charting motions of tectonic plates and movements of volcanoes. Permanent, corrected, constantly-running GPS base stations might be able to achieve this level of accuracy.\n",
    "- The ninth decimal place is worth up to 110 microns: we are getting into the range of microscopy. For almost any conceivable application with earth positions, this is overkill and will be more precise than the accuracy of any surveying device.\n",
    "- Ten or more decimal places indicates a computer or calculator was used and that no attention was paid to the fact that the extra decimals are useless. Be careful, because unless you are the one reading these numbers off the device, this can indicate low quality processing!\n",
    "\n",
    "In this dataset if we want an industry best practice of k=5 but also want a location accuracy of 110 metres (3 decimal points) then we would have to strip out 99.9% of the records, which would make the dataset potentially useless for any meaningful analytics. Let us modify the dataset to have the property of k=5 for location data with 2 digit accuracy (1.1 km) by setting all location points that are more precise than that to \"missing\" which in python and pandas is represented generically by \"NaN\".\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Mask all data that does not meet the wanted k-anonymity value\n",
    "def setMissing(master_df, df, freq_cols, threshold):\n",
    "\n",
    "    new_master_df = master_df.copy()\n",
    "\n",
    "    frequencies = df[freq_cols].value_counts()\n",
    "    condition = frequencies <= threshold  # you can define it however you want\n",
    "    mask_obs = frequencies[condition].index.to_frame()\n",
    "\n",
    "    new_master_index = df.set_index(freq_cols).index\n",
    "    mask_index = mask_obs.set_index(freq_cols).index\n",
    "    new_master_df.loc[new_master_index.isin(mask_index), freq_cols] = np.nan\n",
    "    return new_master_df\n",
    "\n",
    "\n",
    "freq_cols = [\"Pickup_long\", \"Pickup_lat\", \"Dropoff_long\", \"Dropoff_lat\"]\n",
    "threshold = 5\n",
    "\n",
    "working_df = master_df.copy()\n",
    "working_df[freq_cols] = working_df[freq_cols].round(decimals=2)\n",
    "new_master_df = setMissing(master_df, working_df, freq_cols, threshold)\n",
    "\n",
    "new_master_df.info()\n",
    "\n",
    "# Call create_k_anon_matrix for re- analysis\n",
    "\n",
    "k_anon_values = [2, 5, 10, 50, 100, 1000]\n",
    "gps_loc = new_master_df[[\"Pickup_long\", \"Pickup_lat\", \"Dropoff_long\", \"Dropoff_lat\"]].copy()\n",
    "result = create_k_anon_matrix(gps_loc, gps_reduce, k_anon_values)\n",
    "\n",
    "result.style.format(\"{:,.1f}%\").set_caption(\n",
    "        \"% K-Anon Compliance: x = k value, rows = gps decimal points\\n Dataset size = \" + str(len (gps_loc))\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   Pickup             Dropoff  Pickup_long  Pickup_lat  \\\n",
      "0     2015-01-15 19:05:39 2015-01-15 19:23:42   -73.993896   40.750111   \n",
      "1     2015-01-10 20:33:38 2015-01-10 20:53:28   -74.001648   40.724243   \n",
      "2     2015-01-10 20:33:38 2015-01-10 20:43:41   -73.963341   40.802788   \n",
      "3     2015-01-10 20:33:39 2015-01-10 20:35:31   -74.009087   40.713818   \n",
      "4     2015-01-10 20:33:39 2015-01-10 20:52:58   -73.971176   40.762428   \n",
      "...                   ...                 ...          ...         ...   \n",
      "97945 2015-01-21 18:16:49 2015-01-21 18:21:27   -73.986488   40.740021   \n",
      "97946 2015-01-21 18:16:49 2015-01-21 19:11:10   -74.003777   40.731682   \n",
      "97947 2015-01-21 18:16:49 2015-01-21 18:26:51   -74.007477   40.708118   \n",
      "97948 2015-01-21 18:16:50 2015-01-21 19:28:34          NaN         NaN   \n",
      "97949 2015-01-21 18:16:50 2015-01-21 18:38:15   -73.996353   40.725224   \n",
      "\n",
      "       Dropoff_long  Dropoff_lat Sex        DOB  \n",
      "0        -73.974785    40.750618   M 1968-08-04  \n",
      "1        -73.994415    40.759109   F 1980-07-23  \n",
      "2        -73.951820    40.824413   M 1996-07-06  \n",
      "3        -74.004326    40.719986   F 1964-08-23  \n",
      "4        -74.004181    40.742653   F 1987-05-25  \n",
      "...             ...          ...  ..        ...  \n",
      "97945    -73.988098    40.732056   M 1966-06-19  \n",
      "97946    -73.783485    40.643738   M 1979-05-18  \n",
      "97947    -74.009270    40.718620   M 1978-12-11  \n",
      "97948           NaN          NaN   M 1990-02-23  \n",
      "97949    -73.981247    40.759380   M 1992-12-29  \n",
      "\n",
      "[97950 rows x 8 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97950 entries, 0 to 97949\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Pickup        97950 non-null  datetime64[ns]\n",
      " 1   Dropoff       97950 non-null  datetime64[ns]\n",
      " 2   Pickup_long   85461 non-null  float64       \n",
      " 3   Pickup_lat    85461 non-null  float64       \n",
      " 4   Dropoff_long  85461 non-null  float64       \n",
      " 5   Dropoff_lat   85461 non-null  float64       \n",
      " 6   Sex           97950 non-null  object        \n",
      " 7   DOB           97950 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(4), object(1)\n",
      "memory usage: 6.0+ MB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11cd4cb70>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b4b54_\">\n",
       "  <caption>% K-Anon Compliance: x = k value, rows = gps decimal points\n",
       " Dataset size = 97950</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >2</th>\n",
       "      <th class=\"col_heading level0 col1\" >5</th>\n",
       "      <th class=\"col_heading level0 col2\" >10</th>\n",
       "      <th class=\"col_heading level0 col3\" >50</th>\n",
       "      <th class=\"col_heading level0 col4\" >100</th>\n",
       "      <th class=\"col_heading level0 col5\" >1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b54_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b4b54_row0_col0\" class=\"data row0 col0\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row0_col1\" class=\"data row0 col1\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row0_col2\" class=\"data row0 col2\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row0_col3\" class=\"data row0 col3\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row0_col4\" class=\"data row0 col4\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row0_col5\" class=\"data row0 col5\" >100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b54_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b4b54_row1_col0\" class=\"data row1 col0\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row1_col1\" class=\"data row1 col1\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row1_col2\" class=\"data row1 col2\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row1_col3\" class=\"data row1 col3\" >99.7%</td>\n",
       "      <td id=\"T_b4b54_row1_col4\" class=\"data row1 col4\" >99.6%</td>\n",
       "      <td id=\"T_b4b54_row1_col5\" class=\"data row1 col5\" >96.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b54_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b4b54_row2_col0\" class=\"data row2 col0\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row2_col1\" class=\"data row2 col1\" >100.0%</td>\n",
       "      <td id=\"T_b4b54_row2_col2\" class=\"data row2 col2\" >95.0%</td>\n",
       "      <td id=\"T_b4b54_row2_col3\" class=\"data row2 col3\" >71.0%</td>\n",
       "      <td id=\"T_b4b54_row2_col4\" class=\"data row2 col4\" >47.9%</td>\n",
       "      <td id=\"T_b4b54_row2_col5\" class=\"data row2 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b54_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b4b54_row3_col0\" class=\"data row3 col0\" >7.6%</td>\n",
       "      <td id=\"T_b4b54_row3_col1\" class=\"data row3 col1\" >0.2%</td>\n",
       "      <td id=\"T_b4b54_row3_col2\" class=\"data row3 col2\" >0.0%</td>\n",
       "      <td id=\"T_b4b54_row3_col3\" class=\"data row3 col3\" >0.0%</td>\n",
       "      <td id=\"T_b4b54_row3_col4\" class=\"data row3 col4\" >0.0%</td>\n",
       "      <td id=\"T_b4b54_row3_col5\" class=\"data row3 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4b54_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b4b54_row4_col0\" class=\"data row4 col0\" >0.1%</td>\n",
       "      <td id=\"T_b4b54_row4_col1\" class=\"data row4 col1\" >0.0%</td>\n",
       "      <td id=\"T_b4b54_row4_col2\" class=\"data row4 col2\" >0.0%</td>\n",
       "      <td id=\"T_b4b54_row4_col3\" class=\"data row4 col3\" >0.0%</td>\n",
       "      <td id=\"T_b4b54_row4_col4\" class=\"data row4 col4\" >0.0%</td>\n",
       "      <td id=\"T_b4b54_row4_col5\" class=\"data row4 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are now going to lock in on 2 decimal points in the new dataset and run another analysis to get the precise k-anonymity value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "new_master_df[freq_cols] = new_master_df[freq_cols].round(decimals=2)\n",
    "\n",
    "def analyse_table_k_anon(df):\n",
    "\n",
    "    print(\"-----------------------\")\n",
    "    print(\"Dataset K-Anon Analysis\")\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    print(\"Dataset size = \", len(df))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    print(\"K-Anonymity Min to Max Values\")\n",
    "    groupings = df.value_counts(ascending=True).reset_index(name='freq')\n",
    "    \n",
    "    display (groupings)\n",
    "\n",
    "    print(\"-----------------------\")\n",
    "    print(\n",
    "        \"Overall K-Anonymity Classification for dataset = \", groupings['freq'][0], \"\"\n",
    "    )\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "\n",
    "analyse_table_k_anon(new_master_df[freq_cols])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Dataset K-Anon Analysis\n",
      "-----------------------\n",
      "Dataset size =  97950\n",
      "-----------------------\n",
      "K-Anonymity Min to Max Values\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "      Pickup_long  Pickup_lat  Dropoff_long  Dropoff_lat  freq\n",
       "0          -73.97       40.76        -73.94        40.81     6\n",
       "1          -74.01       40.74        -73.97        40.79     6\n",
       "2          -73.98       40.79        -74.00        40.74     6\n",
       "3          -74.01       40.74        -73.96        40.78     6\n",
       "4          -73.98       40.78        -73.94        40.80     6\n",
       "...           ...         ...           ...          ...   ...\n",
       "2058       -73.96       40.77        -73.97        40.76   447\n",
       "2059       -73.99       40.75        -73.98        40.75   464\n",
       "2060       -73.98       40.76        -73.99        40.75   478\n",
       "2061       -73.97       40.76        -73.96        40.77   520\n",
       "2062       -73.99       40.75        -73.98        40.76   562\n",
       "\n",
       "[2063 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pickup_long</th>\n",
       "      <th>Pickup_lat</th>\n",
       "      <th>Dropoff_long</th>\n",
       "      <th>Dropoff_lat</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.97</td>\n",
       "      <td>40.76</td>\n",
       "      <td>-73.94</td>\n",
       "      <td>40.81</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-74.01</td>\n",
       "      <td>40.74</td>\n",
       "      <td>-73.97</td>\n",
       "      <td>40.79</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.98</td>\n",
       "      <td>40.79</td>\n",
       "      <td>-74.00</td>\n",
       "      <td>40.74</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-74.01</td>\n",
       "      <td>40.74</td>\n",
       "      <td>-73.96</td>\n",
       "      <td>40.78</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.98</td>\n",
       "      <td>40.78</td>\n",
       "      <td>-73.94</td>\n",
       "      <td>40.80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>-73.96</td>\n",
       "      <td>40.77</td>\n",
       "      <td>-73.97</td>\n",
       "      <td>40.76</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>-73.99</td>\n",
       "      <td>40.75</td>\n",
       "      <td>-73.98</td>\n",
       "      <td>40.75</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>-73.98</td>\n",
       "      <td>40.76</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>40.75</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>-73.97</td>\n",
       "      <td>40.76</td>\n",
       "      <td>-73.96</td>\n",
       "      <td>40.77</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>-73.99</td>\n",
       "      <td>40.75</td>\n",
       "      <td>-73.98</td>\n",
       "      <td>40.76</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2063 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Overall K-Anonymity Classification for dataset =  6 \n",
      "-----------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Knowledge Check 1\n",
    "\n",
    "Enable the knowledge_check_1_df to have k-anonymity of 10 with 2 decimal places, by altering the below code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "freq_cols = [\"Pickup_long\", \"Pickup_lat\", \"Dropoff_long\", \"Dropoff_lat\"]\n",
    "threshold = 5\n",
    "\n",
    "working_df = master_df.copy()\n",
    "working_df[freq_cols] = working_df[freq_cols].round(decimals=2)\n",
    "new_master_df = setMissing(master_df, working_df, freq_cols, threshold)\n",
    "\n",
    "new_master_df.info()\n",
    "\n",
    "# Call create_k_anon_matrix for re- analysis\n",
    "\n",
    "k_anon_values = [2, 5, 10, 50, 100, 1000]\n",
    "gps_loc = new_master_df[[\"Pickup_long\", \"Pickup_lat\", \"Dropoff_long\", \"Dropoff_lat\"]].copy()\n",
    "knowledge_check_1_df = create_k_anon_matrix(gps_loc, gps_reduce, k_anon_values)\n",
    "\n",
    "display(knowledge_check_1_df.style.format(\"{:,.1f}%\").set_caption(\n",
    "        \"% K-Anon Compliance: x = k value, rows = gps decimal points\\n Dataset size = \" + str(len (gps_loc))\n",
    "    ))\n",
    "\n",
    "progressCheck.knowledge_check_1(knowledge_check_1_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   Pickup             Dropoff  Pickup_long  Pickup_lat  \\\n",
      "0     2015-01-15 19:05:39 2015-01-15 19:23:42   -73.993896   40.750111   \n",
      "1     2015-01-10 20:33:38 2015-01-10 20:53:28   -74.001648   40.724243   \n",
      "2     2015-01-10 20:33:38 2015-01-10 20:43:41   -73.963341   40.802788   \n",
      "3     2015-01-10 20:33:39 2015-01-10 20:35:31   -74.009087   40.713818   \n",
      "4     2015-01-10 20:33:39 2015-01-10 20:52:58   -73.971176   40.762428   \n",
      "...                   ...                 ...          ...         ...   \n",
      "97945 2015-01-21 18:16:49 2015-01-21 18:21:27   -73.986488   40.740021   \n",
      "97946 2015-01-21 18:16:49 2015-01-21 19:11:10   -74.003777   40.731682   \n",
      "97947 2015-01-21 18:16:49 2015-01-21 18:26:51   -74.007477   40.708118   \n",
      "97948 2015-01-21 18:16:50 2015-01-21 19:28:34          NaN         NaN   \n",
      "97949 2015-01-21 18:16:50 2015-01-21 18:38:15   -73.996353   40.725224   \n",
      "\n",
      "       Dropoff_long  Dropoff_lat Sex        DOB  \n",
      "0        -73.974785    40.750618   M 1968-08-04  \n",
      "1        -73.994415    40.759109   F 1980-07-23  \n",
      "2        -73.951820    40.824413   M 1996-07-06  \n",
      "3        -74.004326    40.719986   F 1964-08-23  \n",
      "4        -74.004181    40.742653   F 1987-05-25  \n",
      "...             ...          ...  ..        ...  \n",
      "97945    -73.988098    40.732056   M 1966-06-19  \n",
      "97946    -73.783485    40.643738   M 1979-05-18  \n",
      "97947    -74.009270    40.718620   M 1978-12-11  \n",
      "97948           NaN          NaN   M 1990-02-23  \n",
      "97949    -73.981247    40.759380   M 1992-12-29  \n",
      "\n",
      "[97950 rows x 8 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97950 entries, 0 to 97949\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Pickup        97950 non-null  datetime64[ns]\n",
      " 1   Dropoff       97950 non-null  datetime64[ns]\n",
      " 2   Pickup_long   85461 non-null  float64       \n",
      " 3   Pickup_lat    85461 non-null  float64       \n",
      " 4   Dropoff_long  85461 non-null  float64       \n",
      " 5   Dropoff_lat   85461 non-null  float64       \n",
      " 6   Sex           97950 non-null  object        \n",
      " 7   DOB           97950 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(4), object(1)\n",
      "memory usage: 6.0+ MB\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11bc5ea90>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_00aa2_\">\n",
       "  <caption>% K-Anon Compliance: x = k value, rows = gps decimal points\n",
       " Dataset size = 97950</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >2</th>\n",
       "      <th class=\"col_heading level0 col1\" >5</th>\n",
       "      <th class=\"col_heading level0 col2\" >10</th>\n",
       "      <th class=\"col_heading level0 col3\" >50</th>\n",
       "      <th class=\"col_heading level0 col4\" >100</th>\n",
       "      <th class=\"col_heading level0 col5\" >1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_00aa2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_00aa2_row0_col0\" class=\"data row0 col0\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row0_col1\" class=\"data row0 col1\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row0_col2\" class=\"data row0 col2\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row0_col3\" class=\"data row0 col3\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row0_col4\" class=\"data row0 col4\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row0_col5\" class=\"data row0 col5\" >100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00aa2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_00aa2_row1_col0\" class=\"data row1 col0\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row1_col1\" class=\"data row1 col1\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row1_col2\" class=\"data row1 col2\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row1_col3\" class=\"data row1 col3\" >99.7%</td>\n",
       "      <td id=\"T_00aa2_row1_col4\" class=\"data row1 col4\" >99.6%</td>\n",
       "      <td id=\"T_00aa2_row1_col5\" class=\"data row1 col5\" >96.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00aa2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_00aa2_row2_col0\" class=\"data row2 col0\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row2_col1\" class=\"data row2 col1\" >100.0%</td>\n",
       "      <td id=\"T_00aa2_row2_col2\" class=\"data row2 col2\" >95.0%</td>\n",
       "      <td id=\"T_00aa2_row2_col3\" class=\"data row2 col3\" >71.0%</td>\n",
       "      <td id=\"T_00aa2_row2_col4\" class=\"data row2 col4\" >47.9%</td>\n",
       "      <td id=\"T_00aa2_row2_col5\" class=\"data row2 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00aa2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_00aa2_row3_col0\" class=\"data row3 col0\" >7.6%</td>\n",
       "      <td id=\"T_00aa2_row3_col1\" class=\"data row3 col1\" >0.2%</td>\n",
       "      <td id=\"T_00aa2_row3_col2\" class=\"data row3 col2\" >0.0%</td>\n",
       "      <td id=\"T_00aa2_row3_col3\" class=\"data row3 col3\" >0.0%</td>\n",
       "      <td id=\"T_00aa2_row3_col4\" class=\"data row3 col4\" >0.0%</td>\n",
       "      <td id=\"T_00aa2_row3_col5\" class=\"data row3 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00aa2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_00aa2_row4_col0\" class=\"data row4 col0\" >0.1%</td>\n",
       "      <td id=\"T_00aa2_row4_col1\" class=\"data row4 col1\" >0.0%</td>\n",
       "      <td id=\"T_00aa2_row4_col2\" class=\"data row4 col2\" >0.0%</td>\n",
       "      <td id=\"T_00aa2_row4_col3\" class=\"data row4 col3\" >0.0%</td>\n",
       "      <td id=\"T_00aa2_row4_col4\" class=\"data row4 col4\" >0.0%</td>\n",
       "      <td id=\"T_00aa2_row4_col5\" class=\"data row4 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(Button(description='Check Result', style=ButtonStyle()), Output()))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64850c10d1d442caadd290ecb4869b49"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Knowledge Check 2\n",
    "\n",
    "Enable the knowledge_check_2_df to have k-anonymity of 1000 with 1 decimal places, by altering the below code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "freq_cols = [\"Pickup_long\", \"Pickup_lat\", \"Dropoff_long\", \"Dropoff_lat\"]\n",
    "threshold = 5\n",
    "\n",
    "working_df = master_df.copy()\n",
    "working_df[freq_cols] = working_df[freq_cols].round(decimals=2)\n",
    "new_master_df = setMissing(master_df, working_df, freq_cols, threshold)\n",
    "\n",
    "new_master_df.info()\n",
    "\n",
    "# Call create_k_anon_matrix for re- analysis\n",
    "\n",
    "k_anon_values = [2, 5, 10, 50, 100, 1000]\n",
    "gps_loc = new_master_df[[\"Pickup_long\", \"Pickup_lat\", \"Dropoff_long\", \"Dropoff_lat\"]].copy()\n",
    "knowledge_check_2_df = create_k_anon_matrix(gps_loc, gps_reduce, k_anon_values)\n",
    "\n",
    "display(knowledge_check_2_df.style.format(\"{:,.1f}%\").set_caption(\n",
    "        \"% K-Anon Compliance: x = k value, rows = gps decimal points\\n Dataset size = \" + str(len (gps_loc))\n",
    "    ))\n",
    "\n",
    "progressCheck.knowledge_check_2(knowledge_check_2_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   Pickup             Dropoff  Pickup_long  Pickup_lat  \\\n",
      "0     2015-01-15 19:05:39 2015-01-15 19:23:42   -73.993896   40.750111   \n",
      "1     2015-01-10 20:33:38 2015-01-10 20:53:28   -74.001648   40.724243   \n",
      "2     2015-01-10 20:33:38 2015-01-10 20:43:41   -73.963341   40.802788   \n",
      "3     2015-01-10 20:33:39 2015-01-10 20:35:31   -74.009087   40.713818   \n",
      "4     2015-01-10 20:33:39 2015-01-10 20:52:58   -73.971176   40.762428   \n",
      "...                   ...                 ...          ...         ...   \n",
      "97945 2015-01-21 18:16:49 2015-01-21 18:21:27   -73.986488   40.740021   \n",
      "97946 2015-01-21 18:16:49 2015-01-21 19:11:10   -74.003777   40.731682   \n",
      "97947 2015-01-21 18:16:49 2015-01-21 18:26:51   -74.007477   40.708118   \n",
      "97948 2015-01-21 18:16:50 2015-01-21 19:28:34          NaN         NaN   \n",
      "97949 2015-01-21 18:16:50 2015-01-21 18:38:15   -73.996353   40.725224   \n",
      "\n",
      "       Dropoff_long  Dropoff_lat Sex        DOB  \n",
      "0        -73.974785    40.750618   M 1968-08-04  \n",
      "1        -73.994415    40.759109   F 1980-07-23  \n",
      "2        -73.951820    40.824413   M 1996-07-06  \n",
      "3        -74.004326    40.719986   F 1964-08-23  \n",
      "4        -74.004181    40.742653   F 1987-05-25  \n",
      "...             ...          ...  ..        ...  \n",
      "97945    -73.988098    40.732056   M 1966-06-19  \n",
      "97946    -73.783485    40.643738   M 1979-05-18  \n",
      "97947    -74.009270    40.718620   M 1978-12-11  \n",
      "97948           NaN          NaN   M 1990-02-23  \n",
      "97949    -73.981247    40.759380   M 1992-12-29  \n",
      "\n",
      "[97950 rows x 8 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97950 entries, 0 to 97949\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Pickup        97950 non-null  datetime64[ns]\n",
      " 1   Dropoff       97950 non-null  datetime64[ns]\n",
      " 2   Pickup_long   85461 non-null  float64       \n",
      " 3   Pickup_lat    85461 non-null  float64       \n",
      " 4   Dropoff_long  85461 non-null  float64       \n",
      " 5   Dropoff_lat   85461 non-null  float64       \n",
      " 6   Sex           97950 non-null  object        \n",
      " 7   DOB           97950 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(4), object(1)\n",
      "memory usage: 6.0+ MB\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11cd4c3c8>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_799a3_\">\n",
       "  <caption>% K-Anon Compliance: x = k value, rows = gps decimal points\n",
       " Dataset size = 97950</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >2</th>\n",
       "      <th class=\"col_heading level0 col1\" >5</th>\n",
       "      <th class=\"col_heading level0 col2\" >10</th>\n",
       "      <th class=\"col_heading level0 col3\" >50</th>\n",
       "      <th class=\"col_heading level0 col4\" >100</th>\n",
       "      <th class=\"col_heading level0 col5\" >1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_799a3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_799a3_row0_col0\" class=\"data row0 col0\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row0_col1\" class=\"data row0 col1\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row0_col2\" class=\"data row0 col2\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row0_col3\" class=\"data row0 col3\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row0_col4\" class=\"data row0 col4\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row0_col5\" class=\"data row0 col5\" >100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_799a3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_799a3_row1_col0\" class=\"data row1 col0\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row1_col1\" class=\"data row1 col1\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row1_col2\" class=\"data row1 col2\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row1_col3\" class=\"data row1 col3\" >99.7%</td>\n",
       "      <td id=\"T_799a3_row1_col4\" class=\"data row1 col4\" >99.6%</td>\n",
       "      <td id=\"T_799a3_row1_col5\" class=\"data row1 col5\" >96.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_799a3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_799a3_row2_col0\" class=\"data row2 col0\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row2_col1\" class=\"data row2 col1\" >100.0%</td>\n",
       "      <td id=\"T_799a3_row2_col2\" class=\"data row2 col2\" >95.0%</td>\n",
       "      <td id=\"T_799a3_row2_col3\" class=\"data row2 col3\" >71.0%</td>\n",
       "      <td id=\"T_799a3_row2_col4\" class=\"data row2 col4\" >47.9%</td>\n",
       "      <td id=\"T_799a3_row2_col5\" class=\"data row2 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_799a3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_799a3_row3_col0\" class=\"data row3 col0\" >7.6%</td>\n",
       "      <td id=\"T_799a3_row3_col1\" class=\"data row3 col1\" >0.2%</td>\n",
       "      <td id=\"T_799a3_row3_col2\" class=\"data row3 col2\" >0.0%</td>\n",
       "      <td id=\"T_799a3_row3_col3\" class=\"data row3 col3\" >0.0%</td>\n",
       "      <td id=\"T_799a3_row3_col4\" class=\"data row3 col4\" >0.0%</td>\n",
       "      <td id=\"T_799a3_row3_col5\" class=\"data row3 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_799a3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_799a3_row4_col0\" class=\"data row4 col0\" >0.1%</td>\n",
       "      <td id=\"T_799a3_row4_col1\" class=\"data row4 col1\" >0.0%</td>\n",
       "      <td id=\"T_799a3_row4_col2\" class=\"data row4 col2\" >0.0%</td>\n",
       "      <td id=\"T_799a3_row4_col3\" class=\"data row4 col3\" >0.0%</td>\n",
       "      <td id=\"T_799a3_row4_col4\" class=\"data row4 col4\" >0.0%</td>\n",
       "      <td id=\"T_799a3_row4_col5\" class=\"data row4 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(Button(description='Check Result', style=ButtonStyle()), Output()))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38b6e0d6a75d4a60905af17fe99409a7"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### L-Diversity\n",
    "\n",
    "We are now going to look at the l-diversity in the new master dataset.  For every pickup location there should be \"l\" dropoff locations and for every dropoff location there should be \"l\" pickup locations where l > 1. For example an l-diversity of 2 says there should be at least two dropoff locations for every pickup location and vice versa."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def l_diversity_analysis(df, columns):\n",
    "\n",
    "    lowest_l = None\n",
    "\n",
    "    print(\"-----------------------\")\n",
    "    print(\"Dataset L-Diversity Analysis\")\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    print(\"Dataset Information\")\n",
    "    df.info()\n",
    "    print(\"-----------------------\")\n",
    "    print(\"Dataset size = \", len(df))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    for col in columns:\n",
    "        freq = working_df[col].value_counts(ascending=True)\n",
    "        print(freq)\n",
    "\n",
    "        print(\"\\n-----------------------\")\n",
    "        print(\"L-Diversity Min to Max Values: \", col)\n",
    "        groupings = df.value_counts(ascending=True)\n",
    "\n",
    "        if lowest_l == None:\n",
    "            lowest_l = freq.values[0]\n",
    "        elif lowest_l > freq.values[0]:\n",
    "            lowest_l = freq.values[0]\n",
    "\n",
    "    print(\"-----------------------\")\n",
    "    print(\"Overall L-Diversity for dataset = \", lowest_l)\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "\n",
    "working_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Pickup_gps\": pd.Series([], dtype=\"object\"),\n",
    "        \"Dropoff_gps\": pd.Series([], dtype=\"object\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "working_df[\"Pickup_gps\"] = list(\n",
    "    zip(new_master_df[\"Pickup_long\"], new_master_df[\"Pickup_lat\"])\n",
    ")\n",
    "working_df[\"Dropoff_gps\"] = list(\n",
    "    zip(new_master_df[\"Dropoff_long\"], new_master_df[\"Dropoff_lat\"])\n",
    ")\n",
    "\n",
    "l_diversity_analysis(working_df, [\"Pickup_gps\", \"Dropoff_gps\"])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Dataset L-Diversity Analysis\n",
      "-----------------------\n",
      "Dataset Information\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97950 entries, 0 to 97949\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Pickup_gps   97950 non-null  object\n",
      " 1   Dropoff_gps  97950 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.5+ MB\n",
      "-----------------------\n",
      "Dataset size =  97950\n",
      "-----------------------\n",
      "(-73.993896484375, 40.7501106262207)            1\n",
      "(-74.00082397460938, 40.747161865234375)        1\n",
      "(-73.98677825927734, 40.7641716003418)          1\n",
      "(-73.9846954345703, 40.72883224487305)          1\n",
      "(-73.9492645263672, 40.78155517578125)          1\n",
      "                                            ...  \n",
      "(-73.9940414428711, 40.751258850097656)         3\n",
      "(-73.91512298583984, 40.74357604980469)         5\n",
      "(-74.00314331054686, 40.72767639160156)         5\n",
      "(-73.94863891601561, 40.74489974975586)         8\n",
      "(nan, nan)                                  12489\n",
      "Name: Pickup_gps, Length: 85177, dtype: int64\n",
      "\n",
      "-----------------------\n",
      "L-Diversity Min to Max Values:  Pickup_gps\n",
      "(-73.97478485107422, 40.75061798095703)        1\n",
      "(-73.95242309570312, 40.77278137207031)        1\n",
      "(-73.99382781982422, 40.72089385986328)        1\n",
      "(-74.0026092529297, 40.73390579223633)         1\n",
      "(-73.9952392578125, 40.72222137451172)         1\n",
      "                                           ...  \n",
      "(-74.007568359375, 40.74095916748047)          3\n",
      "(-74.00314331054686, 40.72767639160156)        5\n",
      "(-73.91512298583984, 40.74357604980469)        5\n",
      "(-73.94863891601561, 40.74489974975586)        8\n",
      "(nan, nan)                                 12489\n",
      "Name: Dropoff_gps, Length: 85269, dtype: int64\n",
      "\n",
      "-----------------------\n",
      "L-Diversity Min to Max Values:  Dropoff_gps\n",
      "-----------------------\n",
      "Overall L-Diversity for dataset =  1\n",
      "-----------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pickup Analysis\n",
    "\n",
    "We are now going to use the same orginal dataset and focus on demographics of passengers relating to pickup locations and times only.  \n",
    "\n",
    "We are going to use the columns DOB, Sex, Pickup, Pickup_long and Pickup_lat"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "pickup_columns = [\"DOB\", \"Sex\", \"Pickup\", \"Pickup_long\", \"Pickup_lat\"]\n",
    "working_df = master_df[pickup_columns].copy()\n",
    "\n",
    "print(working_df.head(3))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         DOB Sex              Pickup  Pickup_long  Pickup_lat\n",
      "0 1968-08-04   M 2015-01-15 19:05:39   -73.993896   40.750111\n",
      "1 1980-07-23   F 2015-01-10 20:33:38   -74.001648   40.724243\n",
      "2 1996-07-06   M 2015-01-10 20:33:38   -73.963341   40.802788\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's run k-anonymity analysis on this dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "analyse_table_k_anon(working_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Dataset K-Anon Analysis\n",
      "-----------------------\n",
      "Dataset size =  97950\n",
      "-----------------------\n",
      "K-Anonymity Min to Max Values\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "             DOB Sex              Pickup  Pickup_long  Pickup_lat  freq\n",
       "0     1955-08-01   F 2015-01-10 01:06:28   -73.968590   40.756573     1\n",
       "1     1985-08-31   F 2015-01-17 08:58:13   -73.961151   40.801994     1\n",
       "2     1985-08-31   F 2015-01-09 19:27:55   -73.949570   40.777069     1\n",
       "3     1985-08-31   F 2015-01-06 22:17:29   -74.008919   40.716106     1\n",
       "4     1985-08-30   M 2015-01-31 19:13:11   -73.966476   40.757915     1\n",
       "...          ...  ..                 ...          ...         ...   ...\n",
       "97945 1970-07-28   F 2015-01-12 12:09:32   -73.981857   40.748798     1\n",
       "97946 1970-07-28   F 2015-01-06 17:46:43   -73.953224   40.767941     1\n",
       "97947 1970-07-28   F 2015-01-06 08:54:38   -73.969208   40.763103     1\n",
       "97948 1970-07-29   F 2015-01-05 07:37:26   -73.944969   40.774799     1\n",
       "97949 2000-07-30   M 2015-01-24 04:33:17   -73.954376   40.778011     1\n",
       "\n",
       "[97950 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pickup</th>\n",
       "      <th>Pickup_long</th>\n",
       "      <th>Pickup_lat</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955-08-01</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-10 01:06:28</td>\n",
       "      <td>-73.968590</td>\n",
       "      <td>40.756573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985-08-31</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-17 08:58:13</td>\n",
       "      <td>-73.961151</td>\n",
       "      <td>40.801994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985-08-31</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-09 19:27:55</td>\n",
       "      <td>-73.949570</td>\n",
       "      <td>40.777069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985-08-31</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-06 22:17:29</td>\n",
       "      <td>-74.008919</td>\n",
       "      <td>40.716106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985-08-30</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-01-31 19:13:11</td>\n",
       "      <td>-73.966476</td>\n",
       "      <td>40.757915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97945</th>\n",
       "      <td>1970-07-28</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-12 12:09:32</td>\n",
       "      <td>-73.981857</td>\n",
       "      <td>40.748798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97946</th>\n",
       "      <td>1970-07-28</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-06 17:46:43</td>\n",
       "      <td>-73.953224</td>\n",
       "      <td>40.767941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97947</th>\n",
       "      <td>1970-07-28</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-06 08:54:38</td>\n",
       "      <td>-73.969208</td>\n",
       "      <td>40.763103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97948</th>\n",
       "      <td>1970-07-29</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-01-05 07:37:26</td>\n",
       "      <td>-73.944969</td>\n",
       "      <td>40.774799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97949</th>\n",
       "      <td>2000-07-30</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-01-24 04:33:17</td>\n",
       "      <td>-73.954376</td>\n",
       "      <td>40.778011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97950 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Overall K-Anonymity Classification for dataset =  1 \n",
      "-----------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start reducing the specificity of the different data types.\n",
    "\n",
    "We do not need the specific date of birth, let's change this to the year born, to allow age to be approximately calculated."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "working_df['DOB'] = master_df[\"DOB\"].dt.year\n",
    "\n",
    "print(working_df.head(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    DOB Sex              Pickup  Pickup_long  Pickup_lat\n",
      "0  1968   M 2015-01-15 19:05:39   -73.993896   40.750111\n",
      "1  1980   F 2015-01-10 20:33:38   -74.001648   40.724243\n",
      "2  1996   M 2015-01-10 20:33:38   -73.963341   40.802788\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's reduce the pickup date and time to just hour of pickup."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "working_df['Pickup'] = master_df[\"Pickup\"].dt.hour\n",
    "\n",
    "print(working_df.head(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    DOB Sex  Pickup  Pickup_long  Pickup_lat\n",
      "0  1968   M      19   -73.993896   40.750111\n",
      "1  1980   F      20   -74.001648   40.724243\n",
      "2  1996   M      20   -73.963341   40.802788\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's examine the k-anonymity value of DOB, Sex and Pickup fields."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "analyse_table_k_anon(working_df[[\"DOB\", \"Sex\", \"Pickup\"]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Dataset K-Anon Analysis\n",
      "-----------------------\n",
      "Dataset size =  97950\n",
      "-----------------------\n",
      "K-Anonymity Min to Max Values\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "       DOB Sex  Pickup  freq\n",
       "0     1994   F       5     3\n",
       "1     1955   M       4     3\n",
       "2     1955   M       5     3\n",
       "3     1955   F       5     3\n",
       "4     1963   F       4     3\n",
       "...    ...  ..     ...   ...\n",
       "2203  1971   M      19    96\n",
       "2204  1965   F      14    98\n",
       "2205  1963   F      18   100\n",
       "2206  1989   M      19   101\n",
       "2207  1986   F      19   106\n",
       "\n",
       "[2208 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pickup</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1955</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1955</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1963</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>1971</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>1965</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>1963</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>1989</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>1986</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2208 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Overall K-Anonymity Classification for dataset =  3 \n",
      "-----------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Python iteration generator function\n",
    "def custom_round(x, base=5):\n",
    "    return int(base * round(float(x) / base))\n",
    "    \n",
    "def dob_reduce(df):\n",
    "\n",
    "    for year_precision in [1, 5, 10]:\n",
    "        df[\"DOB\"] = df[\"DOB\"].apply(lambda x: custom_round(x, base=year_precision))\n",
    "        print(\"\\n-----------------------\")\n",
    "        print( \"Adjusted dob for precision = \", year_precision)\n",
    "        print(\"-------------------------\")\n",
    "        print (df)\n",
    "        yield year_precision, df\n",
    "\n",
    "# Call the functions for analysis\n",
    "\n",
    "k_anon_values = [2, 5, 10, 50, 100, 1000]\n",
    "result = create_k_anon_matrix(working_df[[\"DOB\", \"Sex\", \"Pickup\"]].copy(), dob_reduce, k_anon_values)\n",
    "\n",
    "result.style.format(\"{:,.1f}%\").set_caption(\n",
    "        \"% K-Anon Compliance: x = k value, rows = age ranges\\n Dataset size = \" + str(len (working_df))\n",
    "    )\n",
    " "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "-----------------------\n",
      "Adjusted dob for precision =  1\n",
      "-------------------------\n",
      "        DOB Sex  Pickup\n",
      "0      1968   M      19\n",
      "1      1980   F      20\n",
      "2      1996   M      20\n",
      "3      1964   F      20\n",
      "4      1987   F      20\n",
      "...     ...  ..     ...\n",
      "97945  1966   M      18\n",
      "97946  1979   M      18\n",
      "97947  1978   M      18\n",
      "97948  1990   M      18\n",
      "97949  1992   M      18\n",
      "\n",
      "[97950 rows x 3 columns]\n",
      "\n",
      "-----------------------\n",
      "Adjusted dob for precision =  5\n",
      "-------------------------\n",
      "        DOB Sex  Pickup\n",
      "0      1970   M      19\n",
      "1      1980   F      20\n",
      "2      1995   M      20\n",
      "3      1965   F      20\n",
      "4      1985   F      20\n",
      "...     ...  ..     ...\n",
      "97945  1965   M      18\n",
      "97946  1980   M      18\n",
      "97947  1980   M      18\n",
      "97948  1990   M      18\n",
      "97949  1990   M      18\n",
      "\n",
      "[97950 rows x 3 columns]\n",
      "\n",
      "-----------------------\n",
      "Adjusted dob for precision =  10\n",
      "-------------------------\n",
      "        DOB Sex  Pickup\n",
      "0      1970   M      19\n",
      "1      1980   F      20\n",
      "2      2000   M      20\n",
      "3      1960   F      20\n",
      "4      1980   F      20\n",
      "...     ...  ..     ...\n",
      "97945  1960   M      18\n",
      "97946  1980   M      18\n",
      "97947  1980   M      18\n",
      "97948  1990   M      18\n",
      "97949  1990   M      18\n",
      "\n",
      "[97950 rows x 3 columns]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11bc5ea90>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_812c4_\">\n",
       "  <caption>% K-Anon Compliance: x = k value, rows = age ranges\n",
       " Dataset size = 97950</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >2</th>\n",
       "      <th class=\"col_heading level0 col1\" >5</th>\n",
       "      <th class=\"col_heading level0 col2\" >10</th>\n",
       "      <th class=\"col_heading level0 col3\" >50</th>\n",
       "      <th class=\"col_heading level0 col4\" >100</th>\n",
       "      <th class=\"col_heading level0 col5\" >1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_812c4_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_812c4_row0_col0\" class=\"data row0 col0\" >100.0%</td>\n",
       "      <td id=\"T_812c4_row0_col1\" class=\"data row0 col1\" >100.0%</td>\n",
       "      <td id=\"T_812c4_row0_col2\" class=\"data row0 col2\" >99.1%</td>\n",
       "      <td id=\"T_812c4_row0_col3\" class=\"data row0 col3\" >64.7%</td>\n",
       "      <td id=\"T_812c4_row0_col4\" class=\"data row0 col4\" >0.3%</td>\n",
       "      <td id=\"T_812c4_row0_col5\" class=\"data row0 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_812c4_level0_row1\" class=\"row_heading level0 row1\" >5</th>\n",
       "      <td id=\"T_812c4_row1_col0\" class=\"data row1 col0\" >100.0%</td>\n",
       "      <td id=\"T_812c4_row1_col1\" class=\"data row1 col1\" >100.0%</td>\n",
       "      <td id=\"T_812c4_row1_col2\" class=\"data row1 col2\" >100.0%</td>\n",
       "      <td id=\"T_812c4_row1_col3\" class=\"data row1 col3\" >98.7%</td>\n",
       "      <td id=\"T_812c4_row1_col4\" class=\"data row1 col4\" >93.5%</td>\n",
       "      <td id=\"T_812c4_row1_col5\" class=\"data row1 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_812c4_level0_row2\" class=\"row_heading level0 row2\" >10</th>\n",
       "      <td id=\"T_812c4_row2_col0\" class=\"data row2 col0\" >100.0%</td>\n",
       "      <td id=\"T_812c4_row2_col1\" class=\"data row2 col1\" >100.0%</td>\n",
       "      <td id=\"T_812c4_row2_col2\" class=\"data row2 col2\" >100.0%</td>\n",
       "      <td id=\"T_812c4_row2_col3\" class=\"data row2 col3\" >99.8%</td>\n",
       "      <td id=\"T_812c4_row2_col4\" class=\"data row2 col4\" >98.2%</td>\n",
       "      <td id=\"T_812c4_row2_col5\" class=\"data row2 col5\" >4.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to choose to round ages to the nearest decade, to give more optionality on location precision.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "working_df[\"DOB\"] = working_df[\"DOB\"].apply(lambda x: custom_round(x, base=10))\n",
    "analyse_table_k_anon(working_df[[\"DOB\", \"Sex\", \"Pickup\"]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Dataset K-Anon Analysis\n",
      "-----------------------\n",
      "Dataset size =  97950\n",
      "-----------------------\n",
      "K-Anonymity Min to Max Values\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "      DOB Sex  Pickup  freq\n",
       "0    2000   F       4    38\n",
       "1    2000   F       5    54\n",
       "2    2000   M       4    57\n",
       "3    2000   M       5    57\n",
       "4    1990   F       5    67\n",
       "..    ...  ..     ...   ...\n",
       "235  1980   F      18   807\n",
       "236  1980   M      19   827\n",
       "237  1960   M      19   827\n",
       "238  1960   F      19   833\n",
       "239  1980   F      19   842\n",
       "\n",
       "[240 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pickup</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1980</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1980</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1960</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1960</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1980</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------\n",
      "Overall K-Anonymity Classification for dataset =  38 \n",
      "-----------------------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us analyze our options for location precision."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Call create_k_anon_matrix for re- analysis\n",
    "\n",
    "# Python iteration generator function\n",
    "def pickup_gps_reduce(df):\n",
    "    for dp in range(5):\n",
    "        gps_reduced = df.copy()\n",
    "        gps_reduced[\"Pickup_long\", \"Pickup_lat\"] = gps_reduced[\"Pickup_long\", \"Pickup_lat\"].round(decimals=dp)\n",
    "        yield dp, gps_reduced\n",
    "\n",
    "k_anon_values = [2, 5, 10, 50, 100, 1000]\n",
    "\n",
    "result = create_k_anon_matrix(working_df.copy(), gps_reduce, k_anon_values)\n",
    "\n",
    "result.style.format(\"{:,.1f}%\").set_caption(\n",
    "        \"% K-Anon Compliance: x = k value, rows = gps decimal points\\n Dataset size = \" + str(len (gps_loc))\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11c77c1d0>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_96a2d_\">\n",
       "  <caption>% K-Anon Compliance: x = k value, rows = gps decimal points\n",
       " Dataset size = 97950</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >2</th>\n",
       "      <th class=\"col_heading level0 col1\" >5</th>\n",
       "      <th class=\"col_heading level0 col2\" >10</th>\n",
       "      <th class=\"col_heading level0 col3\" >50</th>\n",
       "      <th class=\"col_heading level0 col4\" >100</th>\n",
       "      <th class=\"col_heading level0 col5\" >1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_96a2d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_96a2d_row0_col0\" class=\"data row0 col0\" >100.0%</td>\n",
       "      <td id=\"T_96a2d_row0_col1\" class=\"data row0 col1\" >100.0%</td>\n",
       "      <td id=\"T_96a2d_row0_col2\" class=\"data row0 col2\" >100.0%</td>\n",
       "      <td id=\"T_96a2d_row0_col3\" class=\"data row0 col3\" >100.0%</td>\n",
       "      <td id=\"T_96a2d_row0_col4\" class=\"data row0 col4\" >98.6%</td>\n",
       "      <td id=\"T_96a2d_row0_col5\" class=\"data row0 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a2d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_96a2d_row1_col0\" class=\"data row1 col0\" >99.7%</td>\n",
       "      <td id=\"T_96a2d_row1_col1\" class=\"data row1 col1\" >99.1%</td>\n",
       "      <td id=\"T_96a2d_row1_col2\" class=\"data row1 col2\" >98.0%</td>\n",
       "      <td id=\"T_96a2d_row1_col3\" class=\"data row1 col3\" >90.1%</td>\n",
       "      <td id=\"T_96a2d_row1_col4\" class=\"data row1 col4\" >85.2%</td>\n",
       "      <td id=\"T_96a2d_row1_col5\" class=\"data row1 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a2d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_96a2d_row2_col0\" class=\"data row2 col0\" >95.0%</td>\n",
       "      <td id=\"T_96a2d_row2_col1\" class=\"data row2 col1\" >84.7%</td>\n",
       "      <td id=\"T_96a2d_row2_col2\" class=\"data row2 col2\" >67.4%</td>\n",
       "      <td id=\"T_96a2d_row2_col3\" class=\"data row2 col3\" >2.0%</td>\n",
       "      <td id=\"T_96a2d_row2_col4\" class=\"data row2 col4\" >0.0%</td>\n",
       "      <td id=\"T_96a2d_row2_col5\" class=\"data row2 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a2d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_96a2d_row3_col0\" class=\"data row3 col0\" >28.6%</td>\n",
       "      <td id=\"T_96a2d_row3_col1\" class=\"data row3 col1\" >1.1%</td>\n",
       "      <td id=\"T_96a2d_row3_col2\" class=\"data row3 col2\" >0.0%</td>\n",
       "      <td id=\"T_96a2d_row3_col3\" class=\"data row3 col3\" >0.0%</td>\n",
       "      <td id=\"T_96a2d_row3_col4\" class=\"data row3 col4\" >0.0%</td>\n",
       "      <td id=\"T_96a2d_row3_col5\" class=\"data row3 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a2d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_96a2d_row4_col0\" class=\"data row4 col0\" >1.2%</td>\n",
       "      <td id=\"T_96a2d_row4_col1\" class=\"data row4 col1\" >0.0%</td>\n",
       "      <td id=\"T_96a2d_row4_col2\" class=\"data row4 col2\" >0.0%</td>\n",
       "      <td id=\"T_96a2d_row4_col3\" class=\"data row4 col3\" >0.0%</td>\n",
       "      <td id=\"T_96a2d_row4_col4\" class=\"data row4 col4\" >0.0%</td>\n",
       "      <td id=\"T_96a2d_row4_col5\" class=\"data row4 col5\" >0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Homework\n",
    "\n",
    "We are going to stop there. We hope you now understand the importance of continuously investigating any data you intend to share with others, both internally and externally. Data privacy is a continuous process that changes depending on specific data and sharing context.  Feel free to continue to explore and decide what you would do next with the above dataset.\n",
    "\n",
    "Welcome to being a data protector..."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bea06861575e5c19742827531cafa496805c3cbddda5edb83c8123e7b56a25be"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('venv': virtualenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}